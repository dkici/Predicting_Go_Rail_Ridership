{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b004707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a9f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Import Libraries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import strptime\n",
    "import numpy as np\n",
    "import missingno\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from scipy.stats import skew\n",
    "from calendar import day_abbr, month_abbr, mdays\n",
    "import holidays\n",
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6d09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "from prophet import Prophet\n",
    "import statsmodels\n",
    "import datetime as dt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf, pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d7bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prophet\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.plot import plot_cross_validation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c6b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pandas.tseries.offsets import MonthBegin\n",
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "040e7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe2a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a better visualization, I will use this plotting parameters\n",
    "\n",
    "# Get current size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    " \n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 30\n",
    "fig_size[1] = 5\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3206d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_time_series(input_path, ts_path):\n",
    "    # ## Load Data\n",
    "\n",
    "    data =  pd.read_excel(input_path)\n",
    "    print(\"data is loaded!\")\n",
    "    # Stripping out spaces from ends of names, and replacing internal spaces or different characters with \"_\"\n",
    "    data.columns = [col.strip().replace(' ', '_').lower() for col in data.columns]\n",
    "    data.columns = [col.strip().replace('-', '_').lower() for col in data.columns]\n",
    "    data.columns = [col.strip().replace('&', '_').lower() for col in data.columns]\n",
    "    data.columns = [col.strip().replace('/', '_').lower() for col in data.columns]\n",
    "\n",
    "    data= data.replace('[\\$,/]', '', regex=True)\n",
    "\n",
    "    # ## Data Exploration\n",
    "\n",
    "    # Any of the features has null data\n",
    "\n",
    "    # -- There are 5 numeric features (all int): Year, Day, Week Number, Ridership and Total Train Trips    \n",
    "    # -- Year, Month, and Day can be combined to create Date feature\n",
    "    # -- Month, Rail Corridor, Weekend&Holidays/weekday, Station, and Time Period are categorical \n",
    "\n",
    "    categorical_features = data[['month', 'rail_corridor', 'weekend_holidays_weekday', 'station', 'time_period']]\n",
    "\n",
    "    #Summary of the numerical features\n",
    "    numeric_features = data[['year','day','week_number','ridership','total_train_trips']]\n",
    "\n",
    "    # ## Feature Engineering\n",
    "\n",
    "    # Since this is a time series analysis, I create a Date column\n",
    "\n",
    "    data['Month'] = [strptime(str(i), '%B').tm_mon for i in data['month']]\n",
    "    data[\"date\"] = pd.to_datetime(data[['year', 'Month', 'day']])\n",
    "\n",
    "    # data[\"ridership_by_trips\"] = data[\"ridership\"]/data[\"total_train_trips\"]\n",
    "    # data.head()\n",
    "\n",
    "    # Since this is time series data, I will create time series for each different staion in each rail corridors.\n",
    "\n",
    "    data[\"weekend_holidays_weekday\"].unique()\n",
    "\n",
    "    data = data.drop(columns = 'weekend_holidays_weekday')\n",
    "    \n",
    "    df1 = pd.pivot_table(data, values=['ridership', 'total_train_trips'], index=['date'],\n",
    "                       columns=['rail_corridor'], aggfunc=np.sum) #, fill_value=0\n",
    "    df1.columns = [' '.join(col).strip() for col in df1.columns.values]\n",
    "    df1.index.freq = 'd'\n",
    "    missingno.bar(df1)\n",
    "    \n",
    "    df2 = pd.pivot_table(data, values=['ridership', 'total_train_trips'], index=['date'],\n",
    "                       columns=['rail_corridor','station'], aggfunc=np.sum) #, fill_value=0\n",
    "    df2.columns = [' '.join(col).strip() for col in df2.columns.values]\n",
    "    df2.index.freq = 'd'\n",
    "    missingno.bar(df2)\n",
    "    \n",
    "    df3 = pd.pivot_table(data, values=['ridership', 'total_train_trips'], index=['date'],\n",
    "                       columns=['rail_corridor','station', 'time_period'], aggfunc=np.sum) #, fill_value=0\n",
    "    df3.columns = [' '.join(col).strip() for col in df3.columns.values]\n",
    "    df3.index.freq = 'd'\n",
    "    missingno.bar(df3) \n",
    "\n",
    "    \n",
    "    data.to_csv(f\"{ts_path}/Metrolinx_prepocessed_data.csv\")\n",
    "    df1.to_csv(f\"{ts_path}/Rail_Corridor_data.csv\")\n",
    "    df2.to_csv(f\"{ts_path}/Station_data.csv\")\n",
    "    df3.to_csv(f\"{ts_path}/Time_period_data.csv\")\n",
    " \n",
    "\n",
    "    rc_names =[]\n",
    "    rc_st_names = []\n",
    "    rc_st_tp_names = []\n",
    "\n",
    "\n",
    "    # Rail Corridor\n",
    "    for rc in data.rail_corridor.unique(): \n",
    "        df_rc = data[(data[\"rail_corridor\"] == rc)]\n",
    "        df_rc.rail_corridor.unique()\n",
    "\n",
    "        df_rc = pd.pivot_table(df_rc, values=['ridership', 'total_train_trips'], index=['date'],\n",
    "                                               columns=['rail_corridor'], aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "        df_rc.columns = [' '.join(col).strip() for col in df_rc.columns.values]\n",
    "        if len(df_rc) > 1000: #(4*365)*0.75:\n",
    "            rc_names.append(f\"Metrolinx_{rc}_Data\")\n",
    "            df_rc.to_csv(f\"{ts_path}/Metrolinx_{rc}_Data.csv\")\n",
    "\n",
    "        # Rail Corridor and Station\n",
    "        for st in data.station.unique():\n",
    "            df_rc_st = data[(data[\"rail_corridor\"] == rc) & (data[\"station\"] == st)]\n",
    "            df_rc_st = pd.pivot_table(df_rc_st, values=['ridership', 'total_train_trips'], index=['date'],\n",
    "                           columns=['rail_corridor', 'station'], aggfunc=np.sum, fill_value=0)\n",
    "            df_rc_st.columns = [' '.join(col).strip() for col in df_rc_st.columns.values]\n",
    "            if len(df_rc_st) > 1000: #(4*365)*0.75:\n",
    "                rc_st_names.append(f\"Metrolinx_{rc}_{st}_Data\")\n",
    "                df_rc_st.to_csv(f\"{ts_path}/Metrolinx_{rc}_{st}_Data.csv\")\n",
    "\n",
    "            # Rail Corridor, Station, and time_period\n",
    "            for tp in data.time_period.unique():\n",
    "                df_rc_st_tp = data[(data[\"rail_corridor\"] == rc) & (data[\"station\"] == st) & (data[\"time_period\"] == tp)]\n",
    "                df_rc_st_tp = pd.pivot_table(df_rc_st_tp, values=['ridership', 'total_train_trips'], index=['date'],\n",
    "                               columns=['rail_corridor', 'station', 'time_period'], aggfunc=np.sum, fill_value=0)\n",
    "                df_rc_st_tp.columns = [' '.join(col).strip() for col in df_rc_st_tp.columns.values]\n",
    "                if len(df_rc_st_tp) > 1000: #(4*365)*0.75:\n",
    "                    rc_st_tp_names.append(f\"Metrolinx_{rc}_{st}_{tp}_Data\")\n",
    "                    df_rc_st_tp.to_csv(f\"{ts_path}/Metrolinx_{rc}_{st}_{tp}_Data.csv\")\n",
    "        \n",
    "        \n",
    "    return rc_names, rc_st_names, rc_st_tp_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1893b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_timeseries(ts_data_path):\n",
    "    data_all = pd.read_csv(ts_data_path)\n",
    "    print('time series loaded!')\n",
    "    column_names = ['date', 'ridership', 'trips']\n",
    "    data_all.columns = column_names\n",
    "#     print(data_all.head())\n",
    "#\n",
    "#     print(data_all.info())\n",
    "#     print(len(data_all)) \n",
    "    #Imputing missing in the timestamps\n",
    "   \n",
    "    data_all['date'] = pd.to_datetime(data_all['date']) + dt.timedelta(days=1)\n",
    "    data_all = data_all.set_index('date')\n",
    "    data_all = data_all.resample('1D').mean()\n",
    "#     print(data_all.index)\n",
    "\n",
    "    data_all.isnull().sum()\n",
    "    data_all = data_all.fillna('0')\n",
    "#     print(data_all.isnull().sum())\n",
    "\n",
    "#     print(data_all.info())\n",
    "    data_all = data_all.astype(int)\n",
    "#     print(data_all.info())\n",
    "    print(\"Data All: \\n \", data_all.head())\n",
    "    \n",
    "    data = data_all.filter([\"date\",\"ridership\"])\n",
    "    print(\"Data: \\n \", data.head())\n",
    "    \n",
    "    data_regressors = data_all.filter([\"date\", \"trips\"])\n",
    "    print(\"Data Regressors: \\n \", data_regressors.head())\n",
    "    \n",
    "    return data, data_all, data_regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6316615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(true_val, pred_values, model, ts_name):\n",
    "    mse = mean_squared_error(true_val, pred_values)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(true_val, pred_values)\n",
    "    print(f'\\n {ts_name} {model} MSE Error: {mse:11.10}\\n {ts_name} {model}  RMSE Error: {rmse:11.10} \\n {ts_name} {model}  R square: {r2:11.10}' )\n",
    "    return mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec961a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_eda(data):\n",
    "    data.reset_index().plot(x='date', y='ridership', kind='line', grid=1)\n",
    "    plt.pyplot.show()\n",
    "\n",
    "#     adf, pval, usedlag, nobs, crit_vals, icbest =  adfuller(data.ridership.values)\n",
    "#     print('ADF test statistic:', adf)\n",
    "#     print('ADF p-values:', pval)\n",
    "#     print('ADF number of lags used:', usedlag)\n",
    "#     print('ADF number of observations:', nobs)\n",
    "#     print('ADF critical values:', crit_vals)\n",
    "#     print('ADF best information criterion:', icbest)\n",
    "\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    data_decompose_add = seasonal_decompose(data, model='additive')\n",
    "    data_decompose_add.plot().show()\n",
    "\n",
    "    data_decompose_add_resid = data_decompose_add.resid.sum()\n",
    "#     print(\"additive residual\" ,data_decompose_add_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ca1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_adfuller(ts):\n",
    "    # Dickey-Fuller test\n",
    "    result = adfuller(ts, autolag='AIC')\n",
    "    print('Test statistic: ' , result[0])\n",
    "    print('p-value: '  ,result[1])\n",
    "    print('Critical Values:' ,result[4])\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Strong evidence against the null hypothesis\")\n",
    "        print(\"Reject the null hypothesis\")\n",
    "        print(\"Data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"Weak evidence against the null hypothesis\")\n",
    "        print(\"Fail to reject the null hypothesis\")\n",
    "        print(f\"Data has a unit root and is non-stationary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d02c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acf_pacf(ts):    \n",
    "    # ACF and PACF \n",
    "\n",
    "    lag_acf = acf(ts, nlags=20)\n",
    "    lag_pacf = pacf(ts, nlags=40, method='ols')\n",
    "    \n",
    "    # ACF\n",
    "    plt.figure(figsize=(22,10))\n",
    "\n",
    "    plt.subplot(121) \n",
    "    plt.plot(lag_acf)\n",
    "    plt.axhline(y=0,linestyle='--',color='gray')\n",
    "    plt.axhline(y=-1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
    "    plt.axhline(y=1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
    "    plt.title('Autocorrelation Function')\n",
    "\n",
    "    # PACF\n",
    "    plt.subplot(122)\n",
    "    plt.plot(lag_pacf)\n",
    "    plt.axhline(y=0,linestyle='--',color='gray')\n",
    "    plt.axhline(y=-1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
    "    plt.axhline(y=1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
    "    plt.title('Partial Autocorrelation Function')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab861c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_block(verif, start_date, end_date, ax=None): \n",
    "    df = verif.loc[start_date:end_date,:]\n",
    "    df.loc[:,'yhat'].plot(lw=2, ax=ax, color='r', ls='-', label='forecasts')\n",
    "    ax.fill_between(df.index, df.loc[:,'yhat_lower'], df.loc[:,'yhat_upper'], color='coral', alpha=0.3)\n",
    "    df.loc[:,'y'].plot(lw=2, ax=ax, color='steelblue', ls='-', label='observations')\n",
    "    ax.grid(ls=':')\n",
    "    ax.legend(fontsize=15)\n",
    "    [l.set_fontsize(13) for l in ax.xaxis.get_ticklabels()]\n",
    "    [l.set_fontsize(13) for l in ax.yaxis.get_ticklabels()]\n",
    "    ax.set_ylabel('piece number', fontsize=15)\n",
    "    ax.set_xlabel('', fontsize=15)\n",
    "    ax.set_title(f'{start_date} to {end_date}', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e37f8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_index(m, name):\n",
    "    \"\"\"Given the name of a regressor, return its (column) index in the `beta` matrix.\n",
    "    Parameters\n",
    "    ----------\n",
    "    m: Prophet model object, after fitting.\n",
    "    name: Name of the regressor, as passed into the `add_regressor` function.\n",
    "    Returns\n",
    "    -------\n",
    "    The column index of the regressor in the `beta` matrix.\n",
    "    \"\"\"\n",
    "    return np.extract(\n",
    "        m.train_component_cols[name] == 1, m.train_component_cols.index\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14032db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_coefficients(m):\n",
    "    \"\"\"Summarise the coefficients of the extra regressors used in the model.\n",
    "    For additive regressors, the coefficient represents the incremental impact\n",
    "    on `y` of a unit increase in the regressor. For multiplicative regressors,\n",
    "    the incremental impact is equal to `trend(t)` multiplied by the coefficient.\n",
    "    Coefficients are measured on the original scale of the training data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    m: Prophet model object, after fitting.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame containing:\n",
    "    - `regressor`: Name of the regressor\n",
    "    - `regressor_mode`: Whether the regressor has an additive or multiplicative\n",
    "        effect on `y`.\n",
    "    - `center`: The mean of the regressor if it was standardized. Otherwise 0.\n",
    "    - `coef_lower`: Lower bound for the coefficient, estimated from the MCMC samples.\n",
    "        Only different to `coef` if `mcmc_samples > 0`.\n",
    "    - `coef`: Expected value of the coefficient.\n",
    "    - `coef_upper`: Upper bound for the coefficient, estimated from MCMC samples.\n",
    "        Only to different to `coef` if `mcmc_samples > 0`.\n",
    "    \"\"\"\n",
    "    assert len(m.extra_regressors) > 0, 'No extra regressors found.'\n",
    "    coefs = []\n",
    "    for regressor, params in m.extra_regressors.items():\n",
    "        beta = m.params['beta'][:, regressor_index(m, regressor)]\n",
    "        if params['mode'] == 'additive':\n",
    "            coef = beta * m.y_scale / params['std']\n",
    "        else:\n",
    "            coef = beta / params['std']\n",
    "        percentiles = [\n",
    "            (1 - m.interval_width) / 2,\n",
    "            1 - (1 - m.interval_width) / 2,\n",
    "        ]\n",
    "        coef_bounds = np.quantile(coef, q=percentiles)\n",
    "        record = {\n",
    "            'regressor': regressor,\n",
    "            'regressor_mode': params['mode'],\n",
    "            'center': params['mu'],\n",
    "            'coef_lower': coef_bounds[0],\n",
    "            'coef': np.mean(coef),\n",
    "            'coef_upper': coef_bounds[1],\n",
    "        }\n",
    "        coefs.append(record)\n",
    "\n",
    "    return pd.DataFrame(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5040f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustedR2(r2,n,k):\n",
    "    return r2-(k-1)/(n-k)*(1-r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0955c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794aab4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
